{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJQ3XUjFTpip"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pULrqFxUuv_",
        "outputId": "dbadce7f-bf42-4b4c-8f45-d4fc33b80493"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-e-e3smV78R"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "stemmer = SnowballStemmer('spanish')\n",
        "\n",
        "def preprocess(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [stemmer.stem(token) for token in tokens if token not in stop_words]\n",
        "    return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSNIIaXdXOlU",
        "outputId": "52b9e34e-7fe9-4d1b-e06b-0f5a2d0af1be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.39896105 0.39896105 0.39896105 0.39896105 0.60276058 0.\n",
            "  0.        ]\n",
            " [0.361028   0.361028   0.361028   0.361028   0.         0.69183461\n",
            "  0.        ]\n",
            " [0.361028   0.361028   0.361028   0.361028   0.         0.\n",
            "  0.69183461]\n",
            " [0.39896105 0.39896105 0.39896105 0.39896105 0.60276058 0.\n",
            "  0.        ]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Lista de documentos preprocesados\n",
        "documents = [\"este es el primer documento\", \"este es el segundo documento\", \"y este es el tercero documento\", \"¿es este el primer documento?\"]\n",
        "\n",
        "# Crear un objeto TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Crear la matriz TF-IDF\n",
        "tf_idf_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Obtener el vocabulario\n",
        "vocab = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Imprimir la matriz TF-IDF\n",
        "print(tf_idf_matrix.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTNyARbDYxjr",
        "outputId": "b938ba80-a2eb-481f-c534-be3dc3c5f768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La precisión del modelo es: 0.5\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Lista de preguntas etiquetadas\n",
        "preguntas = [\"¿Cómo se hace un pastel?\", \"¿Qué es el cambio climático?\", \"¿Cómo puedo aprender programación?\", \"¿Cuál es la capital de México?\", \"¿Qué es la energía solar?\", \"¿Cuál es el mejor restaurante en Madrid?\"]\n",
        "etiquetas = [\"Cocina\", \"Ciencia\", \"Programación\", \"Geografía\", \"Ciencia\", \"Gastronomía\"]\n",
        "\n",
        "# Dividir las preguntas en conjuntos de entrenamiento y prueba\n",
        "train_preguntas, test_preguntas, train_etiquetas, test_etiquetas = train_test_split(preguntas, etiquetas, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear un objeto TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Crear la matriz TF-IDF para el conjunto de entrenamiento\n",
        "train_tf_idf_matrix = vectorizer.fit_transform(train_preguntas)\n",
        "\n",
        "# Entrenar un modelo LinearSVC\n",
        "model = LinearSVC()\n",
        "model.fit(train_tf_idf_matrix, train_etiquetas)\n",
        "\n",
        "# Crear la matriz TF-IDF para el conjunto de prueba\n",
        "test_tf_idf_matrix = vectorizer.transform(test_preguntas)\n",
        "\n",
        "# Evaluar el modelo\n",
        "accuracy = model.score(test_tf_idf_matrix, test_etiquetas)\n",
        "print(f\"La precisión del modelo es: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwT1-b3pZtd9",
        "outputId": "a8070a85-ee8a-44de-bd28-803ecd60db3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pregunta: ¿Cómo se llama tu perro?\n",
            "Etiqueta: Saludos\n",
            "\n",
            "Pregunta: ¿Qué día es hoy?\n",
            "Etiqueta: Tiempo\n",
            "\n",
            "Pregunta: ¿Cuál es tu comida favorita?\n",
            "Etiqueta: Geografía\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Definir preguntas y etiquetas\n",
        "preguntas = [\"¿Cómo estás?\", \"¿Qué hora es?\", \"¿Cómo te llamas?\", \"¿Cuál es la capital de Francia?\"]\n",
        "etiquetas = [\"Saludos\", \"Tiempo\", \"Nombre\", \"Geografía\"]\n",
        "\n",
        "# Preprocesamiento\n",
        "def preprocesar(texto):\n",
        "    # Pasar todo a minúsculas\n",
        "    texto = texto.lower()\n",
        "    # Quitar puntuación\n",
        "    texto = texto.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Quitar números\n",
        "    texto = re.sub(r'\\d+', '', texto)\n",
        "    # Quitar espacios en blanco adicionales\n",
        "    texto = \" \".join(texto.split())\n",
        "    return texto\n",
        "\n",
        "preguntas_procesadas = [preprocesar(pregunta) for pregunta in preguntas]\n",
        "\n",
        "# Crear matriz TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "matriz_tfidf = vectorizer.fit_transform(preguntas_procesadas)\n",
        "\n",
        "# Entrenar clasificador SVM\n",
        "clf = LinearSVC()\n",
        "clf.fit(matriz_tfidf, etiquetas)\n",
        "\n",
        "# Hacer predicciones\n",
        "preguntas_nuevas = [\"¿Cómo se llama tu perro?\", \"¿Qué día es hoy?\", \"¿Cuál es tu comida favorita?\"]\n",
        "preguntas_nuevas_procesadas = [preprocesar(pregunta) for pregunta in preguntas_nuevas]\n",
        "matriz_tfidf_nuevas = vectorizer.transform(preguntas_nuevas_procesadas)\n",
        "predicciones = clf.predict(matriz_tfidf_nuevas)\n",
        "\n",
        "# Imprimir resultados\n",
        "for pregunta, etiqueta in zip(preguntas_nuevas, predicciones):\n",
        "    print(f\"Pregunta: {pregunta}\\nEtiqueta: {etiqueta}\\n\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ2zYz1_cEq8"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "preguntas = [\n",
        "    '¿Cuál es el nombre del proyecto?',\n",
        "    '¿En qué lenguaje de programación está escrito el proyecto?',\n",
        "    '¿Quiénes son los desarrolladores del proyecto?',\n",
        "    '¿Cuál es el objetivo del proyecto?',\n",
        "    '¿Cuál es la licencia del proyecto?',\n",
        "    '¿Dónde puedo encontrar más información sobre el proyecto?'\n",
        "]\n",
        "\n",
        "respuestas = [\n",
        "    'El nombre del proyecto es Chatbot en español.',\n",
        "    'El proyecto está escrito en Python.',\n",
        "    'El proyecto fue desarrollado por un grupo de estudiantes de programación.',\n",
        "    'El objetivo del proyecto es crear un chatbot que pueda responder preguntas frecuentes.',\n",
        "    'El proyecto está bajo la licencia MIT.',\n",
        "    'Puedes encontrar más información sobre el proyecto en el archivo README.md.'\n",
        "]\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "vectorizer = TfidfVectorizer()\n",
        "clf = SVC(C=1)\n",
        "\n",
        "train_preguntas_preprocesadas = [re.sub(r'[^\\w\\s]', '', pregunta.lower()) for pregunta in preguntas]\n",
        "train_etiquetas = respuestas\n",
        "\n",
        "train_preguntas_vectorizadas = vectorizer.fit_transform(train_preguntas_preprocesadas)\n",
        "\n",
        "clf.fit(train_preguntas_vectorizadas, train_etiquetas)\n",
        "\n",
        "def responder(pregunta):\n",
        "    pregunta_preprocesada = re.sub(r'[^\\w\\s]', '', pregunta.lower())\n",
        "    pregunta_vectorizada = vectorizer.transform([pregunta_preprocesada])\n",
        "    etiqueta_predicha = clf.predict(pregunta_vectorizada)[0]\n",
        "    return etiqueta_predicha\n",
        "\n",
        "# Ejecución del chatbot\n",
        "while True:\n",
        "    pregunta = input('Ingresa tu pregunta: ')\n",
        "    respuesta = responder(pregunta)\n",
        "    print(respuesta)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}